BASE = "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api"
import os
from dotenv import load_dotenv
load_dotenv()
from datetime import datetime
import jsonschema

total_rader = 0
total_funktioner = 0
total_komplexitet = 0
total_todo = 0

# Lista √∂ver filnamn
import glob

filnamn_lista = [
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_from_cloud.py",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_to_cloud.py",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_static_tables.py",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync.py",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_all.py",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_plist.xml",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_generate_fromcloud_pending.py",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_generate_pending_from_diff.py",
    "/Users/danielkallberg/Library/LaunchAgents/com.macspot.sync.plist",
    "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/healthcheck_sync.py"
]

# Slutlig sammanslagen fil
output_fil = os.path.join("/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/AllSyncCodes_history", f"AllSyncCodes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
output_dir = os.path.dirname(output_fil)

saknade_filer = []
# L√§s och skriv inneh√•ll
with open(output_fil, "w", encoding="utf-8") as utfil:
    # Tr√§dstruktur
    from collections import defaultdict

    def bygg_tr√§d(paths):
        tr√§d = lambda: defaultdict(tr√§d)
        rot = tr√§d()
        # L√§gg till extra filer med etiketterade namn
        paths = list(paths)
        paths += [
            os.path.join(output_dir, "üßä_azure_temp.txt"),
            os.path.join(output_dir, "üè†_lokal_temp.txt"),
            os.path.join(output_dir, "üßÆ_diff_output.txt")
        ]
        for path in paths:
            delar = os.path.relpath(path, root_path).split(os.sep)
            curr = rot
            for del_ in delar:
                curr = curr[del_]
        return rot

    def skriv_tr√§d(node, depth=0):
        for namn in sorted(node.keys()):
            prefix = "‚îÇ   " * depth + "‚îú‚îÄ‚îÄ "
            utfil.write(f"{prefix}{namn}\n")
            skriv_tr√§d(node[namn], depth + 1)

    # root_path ska inkludera AllSyncCodes_history ocks√•
    root_path = os.path.commonpath(filnamn_lista + [output_dir])
    # Inkludera √§ven diffdelen och tempfiler i paths
    filtrerat = [f for f in filnamn_lista if "node_modules" not in f]
    paths_for_tree = list(filtrerat)
    paths_for_tree += [
        os.path.join(output_dir, "üßä_azure_temp.txt"),
        os.path.join(output_dir, "üè†_lokal_temp.txt"),
        os.path.join(output_dir, "üßÆ_diff_output.txt")
    ]
    struktur = bygg_tr√§d(paths_for_tree)
    utfil.write("üìÇ KODTR√ÑD\n==========\n")
    skriv_tr√§d(struktur)
    utfil.write("==========\n\n")

    for filnamn in filnamn_lista:
        visat_filnamn = os.path.basename(filnamn)
        rel_path = os.path.relpath(filnamn, root_path)
        # Best√§m kodtyp baserat p√• s√∂kv√§gen
        if "/shared/" in rel_path:
            kodtyp = "üîß Shared-modul"
        elif "/validate_contact/" in rel_path:
            kodtyp = "üì¨ Kontaktvalidering"
        elif "/meeting_types/" in rel_path:
            kodtyp = "üìÖ M√∂testyp-endpoint"
        elif "/getavailableslots/" in rel_path:
            kodtyp = "üß† Slot-generator"
        elif "/refreshCalendarOrigins/" in rel_path:
            kodtyp = "üîÅ Kalender-refresh"
        elif "/refreshTravelTimes/" in rel_path:
            kodtyp = "üöó Restids-refresh"
        elif "/bookings/" in rel_path:
            kodtyp = "üì§ Boknings-API"
        else:
            kodtyp = "üìÑ √ñvrigt"
        if os.path.exists(filnamn):
            # L√§s filens rader
            with open(filnamn, "r", encoding="utf-8") as infil:
                rader = infil.readlines()
            antal_rader = len(rader)
            # Imports
            imports = []
            import_count = 0
            for rad in rader:
                rad_strip = rad.strip()
                if rad_strip.startswith("import "):
                    imports.append(rad_strip)
                    import_count += 1
                elif "require(" in rad_strip:
                    imports.append(rad_strip)
                    import_count += 1

            # Funktioner
            funktion_count = 0
            # L√§ngsta funktion (f√∂renklad heuristik)
            longest_func = 0
            i = 0
            while i < len(rader):
                rad = rader[i].strip()
                is_func = (
                    rad.startswith("function ")
                    or ("const " in rad and "=" in rad and "(" in rad and rad.rstrip().endswith("{"))
                    or ("=>" in rad and ("const " in rad or "let " in rad or "var " in rad))
                )
                if is_func:
                    funktion_count += 1
                    start = i
                    j = i + 1
                    brace_count = 0
                    if "{" in rad:
                        brace_count += rad.count("{")
                        brace_count -= rad.count("}")
                    while j < len(rader):
                        line = rader[j]
                        brace_count += line.count("{")
                        brace_count -= line.count("}")
                        # Slut p√• funktion: n√§r klammern √§r st√§ngd eller tomrad (f√∂renklad)
                        if brace_count <= 0 or line.strip() == "":
                            break
                        j += 1
                    func_len = j - start
                    if func_len > longest_func:
                        longest_func = func_len
                    i = j
                else:
                    i += 1

            # Kommentarst√§ckning
            kommentar_rader = 0
            for rad in rader:
                rad_strip = rad.strip()
                if (
                    rad_strip.startswith("//")
                    or rad_strip.startswith("/*")
                    or rad_strip.startswith("*")
                    or rad_strip.startswith("*/")
                ):
                    kommentar_rader += 1
            # Komplexitetsord
            komplex_ord = ["if", "for", "while", "switch", "try"]
            komplex_count = 0
            for rad in rader:
                for ord in komplex_ord:
                    # Enkla s√∂k (kan ge dubletter om flera per rad)
                    komplex_count += rad.count(f"{ord} ")
                    komplex_count += rad.count(f"{ord}(")
            # TODO/FIXME
            todo_count = 0
            for rad in rader:
                if "TODO" in rad or "FIXME" in rad:
                    todo_count += 1
            # Senast √§ndrad
            senast_andrad_ts = os.path.getmtime(filnamn)
            senast_andrad = datetime.fromtimestamp(senast_andrad_ts).strftime("%Y-%m-%d %H:%M:%S")

            # Best√§m kodspr√•k baserat p√• fil√§ndelse
            if filnamn.endswith(".js"):
                kodspr√•k = "üü® JavaScript"
            elif filnamn.endswith(".py"):
                kodspr√•k = "üêç Python"
            elif filnamn.endswith(".json"):
                kodspr√•k = "üßæ JSON"
            else:
                kodspr√•k = "üìÑ Ok√§nt format"

            total_rader += antal_rader
            total_funktioner += funktion_count
            total_komplexitet += komplex_count
            total_todo += todo_count

            if 'fil_summering' not in locals():
                fil_summering = []
            fil_summering.append([
                visat_filnamn,
                antal_rader,
                funktion_count,
                komplex_count,
                kommentar_rader,
                import_count
            ])

            # Skriv metadata-block
            utfil.write("====================\n")
            utfil.write(f"üìÑ Fil: {rel_path}\n")
            utfil.write(f"üìÇ Kodtyp: {kodtyp}\n")
            utfil.write(f"üóÇ Filtyp: {kodspr√•k}\n")
            utfil.write(f"üìÖ Senast √§ndrad: {senast_andrad}\n")
            utfil.write(f"üìè Antal rader: {antal_rader}\n")
            utfil.write(f"üß© Antal funktioner: {funktion_count}\n")
            utfil.write(f"üí¨ Kommentarst√§ckning: {kommentar_rader} rader ({(kommentar_rader / antal_rader * 100):.1f}%)\n")
            utfil.write(f"üì• Imports: {import_count} ‚Äì {imports if imports else 'Inga'}\n")
            utfil.write(f"üîç L√§ngsta funktion: {longest_func} rader\n")
            utfil.write(f"üß† Komplexitetspo√§ng: {komplex_count}\n")
            utfil.write(f"üß™ TODO/FIXME: {todo_count}\n")
            utfil.write("====================\n")
            utfil.write(f"START: {visat_filnamn}\n")
            with open(filnamn, "r", encoding="utf-8") as infil:
                utfil.write(infil.read())
            utfil.write(f"\nEND: {visat_filnamn}\n\n")
        else:
            utfil.write(f"START: {visat_filnamn}\n")
            utfil.write(f"// ‚ö†Ô∏è Filen '{visat_filnamn}' hittades inte\n")
            utfil.write(f"END: {visat_filnamn}\n\n")
            saknade_filer.append(visat_filnamn)

    # Lista alla relevanta konfigurationsfiler i hela macspot-api
    utfil.write("üìÅ KONFIGURATIONSFILER (function.json / host.json / package.json / .funcignore)\n")
    utfil.write("====================================\n\n")
    config_filer = []
    for filnamn in ["function.json", "host.json", "package.json", ".funcignore"]:
        config_filer += glob.glob(os.path.join(BASE, "**", filnamn), recursive=True)
    config_filer = [f for f in config_filer if "node_modules" not in f]

    host_schema = {
      "type": "object",
      "properties": {
        "version": {"type": "string"},
        "extensionBundle": {
          "type": "object",
          "properties": {
            "id": {"type": "string"},
            "version": {"type": "string"}
          },
          "required": ["id", "version"]
        }
      },
      "required": ["version"]
    }

    if config_filer:
        for config_fil in sorted(config_filer):
            rel_path = os.path.relpath(config_fil, root_path)
            utfil.write(f"üìÑ {rel_path}\n")
            try:
                if os.path.basename(config_fil) == "host.json":
                    import json
                    data = json.load(open(config_fil))
                    jsonschema.validate(instance=data, schema=host_schema)
                with open(config_fil, "r", encoding="utf-8") as cf:
                    for rad in cf:
                        utfil.write("   " + rad)
            except jsonschema.exceptions.ValidationError as ve:
                utfil.write(f"   // ‚ùå Ogiltig host.json: {ve.message}\n")
            except Exception as e:
                utfil.write(f"   // ‚ö†Ô∏è Kunde inte l√§sa filen: {e}\n")
            utfil.write("\n")
    else:
        utfil.write("Inga function.json, host.json, package.json eller .funcignore hittades i projektet.\n\n")

    utfil.write("üìà SUMMERING AV ALLA JS-FILER\n")
    utfil.write("====================================\n")
    utfil.write(f"üìè Totalt antal rader kod: {total_rader}\n")
    utfil.write(f"üß© Totalt antal funktioner: {total_funktioner}\n")
    utfil.write(f"üß† Total komplexitetspo√§ng: {total_komplexitet}\n")
    utfil.write(f"üß™ Antal TODO/FIXME totalt: {total_todo}\n\n")
    utfil.write("üìä Per fil:\n")
    utfil.write("fil,rader,funktioner,komplexitet,kommentarer,imports\n")
    for row in fil_summering:
        utfil.write(",".join(str(x) for x in row) + "\n")

if saknade_filer:
    print("‚ö†Ô∏è F√∂ljande filer hittades inte:")
    for fil in saknade_filer:
        print(f" - {fil}")

# Slutlig sammanslagen fil

import psycopg2

def generera_databasstruktur(output_path, db_config, rubrik, output_dir):
    # Skriv till tempor√§rfil i output_dir
    temp_path = os.path.join(output_dir, output_path)
    try:
        conn = psycopg2.connect(
            dbname=os.environ[db_config["DB_NAME"]],
            user=os.environ[db_config["DB_USER"]],
            password=os.environ[db_config["DB_PASSWORD"]],
            host=os.environ[db_config["DB_HOST"]],
            port=os.environ.get(db_config["DB_PORT"], 5432),
            sslmode=db_config.get("SSLMODE", "disable")
        )
        cur = conn.cursor()
        with open(temp_path, "w", encoding="utf-8") as f:
            f.write(f"{rubrik}\n")
            f.write("====================================\n\n")
            # Tabeller
            cur.execute("""
                SELECT tablename FROM pg_tables WHERE schemaname = 'public'
            """)
            tables = [row[0] for row in cur.fetchall()]
            for table in tables:
                f.write(f"üìÅ Tabell: {table}\n")
                # Kolumner
                cur.execute(f"""
                    SELECT column_name, data_type
                    FROM information_schema.columns
                    WHERE table_name = %s
                """, (table,))
                cols = cur.fetchall()
                for col in cols:
                    f.write(f"  ‚Ä¢ {col[0]} ({col[1]})\n")
                # Prim√§r-/sekund√§rnycklar
                cur.execute("""
                    SELECT conname, contype, pg_get_constraintdef(c.oid)
                    FROM pg_constraint c
                    JOIN pg_class t ON c.conrelid = t.oid
                    WHERE t.relname = %s
                """, (table,))
                keys = cur.fetchall()
                for key in keys:
                    f.write(f"  üîë [{key[1]}] {key[0]}: {key[2]}\n")
                # Top 5 rader
                cur.execute(f"SELECT * FROM {table} LIMIT 5")
                rows = cur.fetchall()
                if rows:
                    colnames = [desc[0] for desc in cur.description]
                    f.write("  üß™ Topp 5 rader:\n")
                    for row in rows:
                        f.write("    - " + ", ".join(f"{k}={v}" for k, v in zip(colnames, row)) + "\n")
                f.write("\n")
        cur.close()
        conn.close()
    except Exception as e:
        print("‚ö†Ô∏è Fel vid h√§mtning av databasstruktur:", e)

import os
# Skriv till tempor√§ra filer i output_dir
generera_databasstruktur("azure_temp.txt", {
    "DB_NAME": "REMOTE_DB_NAME",
    "DB_USER": "REMOTE_DB_USER",
    "DB_PASSWORD": "REMOTE_DB_PASSWORD",
    "DB_HOST": "REMOTE_DB_HOST",
    "DB_PORT": "REMOTE_DB_PORT",
    "SSLMODE": "require"
}, "üìä MOLNDATABAS (Azure) ‚Äì STRUKTUR & INNEH√ÖLL", output_dir)

generera_databasstruktur("lokal_temp.txt", {
    "DB_NAME": "LOCAL_DB_NAME",
    "DB_USER": "LOCAL_DB_USER",
    "DB_PASSWORD": "LOCAL_DB_PASSWORD",
    "DB_HOST": "LOCAL_DB_HOST",
    "DB_PORT": "LOCAL_DB_PORT"
}, "üìä LOKAL DATABAS ‚Äì STRUKTUR & INNEH√ÖLL", output_dir)

from difflib import unified_diff

def generera_diffanalys(fil1, fil2, output_path):
    with open(fil1, "r", encoding="utf-8") as f1, open(fil2, "r", encoding="utf-8") as f2:
        lines1 = f1.readlines()
        lines2 = f2.readlines()
    diff = unified_diff(lines1, lines2, fromfile="Azure", tofile="Lokal", lineterm="")
    with open(output_path, "a", encoding="utf-8") as f:
        f.write("üìä DIFFANALYS Azure vs Lokal\n")
        f.write("====================================\n")
        for line in diff:
            f.write(line + "\n")

# HTML diff-funktion
from difflib import HtmlDiff

def generera_html_diff(fil1, fil2, output_path):
    with open(fil1, "r", encoding="utf-8") as f1, open(fil2, "r", encoding="utf-8") as f2:
        lines1 = f1.readlines()
        lines2 = f2.readlines()
    differ = HtmlDiff()
    html = differ.make_file(lines1, lines2, fromdesc="Azure DB", todesc="Lokal DB", context=True, numlines=3)
    with open(output_path, "w", encoding="utf-8") as out:
        out.write(html)

# Skriv in tempor√§rfilerna till output_fil f√∂re diffen
with open(output_fil, "a", encoding="utf-8") as f:
    for temp_fil in ["azure_temp.txt", "lokal_temp.txt"]:
        temp_path = os.path.join(output_dir, temp_fil)
        with open(temp_path, "r", encoding="utf-8") as tf:
            f.write(tf.read())

generera_diffanalys(
    os.path.join(output_dir, "azure_temp.txt"),
    os.path.join(output_dir, "lokal_temp.txt"),
    output_fil
)

# Anropa HTML-diff direkt efter generera_diffanalys
generera_html_diff(
    os.path.join(output_dir, "azure_temp.txt"),
    os.path.join(output_dir, "lokal_temp.txt"),
    os.path.join(output_dir, "üßÆ_diff_output.html")
)

# Kopiera tempor√§rfiler till etiketterade kopior innan de tas bort
import shutil
shutil.copyfile(os.path.join(output_dir, "azure_temp.txt"), os.path.join(output_dir, "üßä_azure_temp.txt"))
shutil.copyfile(os.path.join(output_dir, "lokal_temp.txt"), os.path.join(output_dir, "üè†_lokal_temp.txt"))
shutil.copyfile(output_fil, os.path.join(output_dir, "üßÆ_diff_output.txt"))

# Ta bort tempor√§ra filer efter diffanalysen

os.remove(os.path.join(output_dir, "azure_temp.txt"))
os.remove(os.path.join(output_dir, "lokal_temp.txt"))

# L√§gg till klickbar l√§nk till HTML-diff i textfilen
with open(output_fil, "a", encoding="utf-8") as f:
    f.write("\nüåê HTML-diff finns √§ven h√§r:\n")
    f.write(f"file://{os.path.join(output_dir, 'üßÆ_diff_output.html')}\n")
