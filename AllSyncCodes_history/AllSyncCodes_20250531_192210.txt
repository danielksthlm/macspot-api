ğŸ“‚ KODTRÃ„D
==========
â”œâ”€â”€ healthcheck_sync.py
â”œâ”€â”€ macspot.sync.plist
â”œâ”€â”€ sync.py
â”œâ”€â”€ sync_all.py
â”œâ”€â”€ sync_from_cloud.py
â”œâ”€â”€ sync_static_tables.py
â”œâ”€â”€ sync_to_cloud.py
==========

====================
ğŸ“„ Fil: sync_from_cloud.py
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ Python
ğŸ“… Senast Ã¤ndrad: 2025-05-31 19:05:48
ğŸ“ Antal rader: 144
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 2 â€“ ['import psycopg2', 'import json']
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 20
ğŸ§ª TODO/FIXME: 0
====================
START: sync_from_cloud.py
import psycopg2
import json
from config import LOCAL_DB_CONFIG, REMOTE_DB_CONFIG

def connect_db(config):
    return psycopg2.connect(**config)

def safe_json_load(data, default={}):
    try:
        return json.loads(data) if isinstance(data, str) else data
    except Exception:
        return default

def metadata_equal(meta1, meta2):
    m1 = safe_json_load(meta1)
    m2 = safe_json_load(meta2)
    return m1 == m2

def apply_change(cur, table, operation, payload):
    try:
        if operation == "INSERT":
            cols = ", ".join(payload.keys())
            placeholders = ", ".join(["%s"] * len(payload))
            sql = f"INSERT INTO {table} ({cols}) VALUES ({placeholders}) ON CONFLICT (id) DO NOTHING"
            cur.execute(sql, [json.dumps(v) if isinstance(v, dict) else v for v in payload.values()])

        elif operation == "UPDATE":
            if table == "contact" and "metadata" in payload:
                local_meta = payload["metadata"]
                cur.execute("SELECT metadata FROM contact WHERE id = %s", (payload["id"],))
                row = cur.fetchone()
                if row and metadata_equal(row[0], local_meta):
                    print(f"â™»ï¸ Ingen skillnad i metadata fÃ¶r {payload['id']}, hoppar UPDATE.")
                    return

            sets = ", ".join([f"{col} = %s" for col in payload if col != "id"])
            values = [json.dumps(payload[col]) if isinstance(payload[col], dict) else payload[col]
                      for col in payload if col != "id"]
            values.append(payload["id"])
            sql = f"UPDATE {table} SET {sets} WHERE id = %s"
            cur.execute(sql, values)

            # Verifiera resultat (endast fÃ¶r kontakt)
            if table == "contact":
                cur.execute("SELECT metadata, updated_at FROM contact WHERE id = %s", [payload["id"]])
                updated_row = cur.fetchone()
                if updated_row:
                    try:
                        metadata = safe_json_load(updated_row[0])
                        address = metadata.get("address", "(ingen adress)")
                    except Exception:
                        address = "(kunde inte tolkas)"
                    print(f"ğŸ§¾ Efter UPDATE: {payload['id']} â†’ {address} @ {updated_row[1]}")
                else:
                    print(f"âš ï¸ UPDATE-verifiering misslyckades: Inget resultat fÃ¶r {payload['id']}")

        elif operation == "DELETE":
            cur.execute(f"DELETE FROM {table} WHERE id = %s", [payload["id"]])

    except Exception as e:
        print(f"âŒ Fel i apply_change fÃ¶r {table} ({operation}): {e}")
        raise

def sync():
    remote_conn = connect_db(REMOTE_DB_CONFIG)
    remote_cur = remote_conn.cursor()

    local_conn = connect_db(LOCAL_DB_CONFIG)
    local_cur = local_conn.cursor()

    try:
        remote_cur.execute("""
            SELECT id, table_name, record_id, operation, payload
            FROM (
                SELECT *, ROW_NUMBER() OVER (PARTITION BY record_id ORDER BY created_at ASC) AS rn
                FROM pending_changes
                WHERE direction = 'out' AND processed = false
                  AND table_name IN ('contact', 'bookings')
            ) sub
            WHERE rn = 1
            ORDER BY created_at ASC, id
        """)
        rows = remote_cur.fetchall()

        remote_cur.execute("""
            DELETE FROM pending_changes
            WHERE id NOT IN (
                SELECT id FROM (
                    SELECT id, ROW_NUMBER() OVER (PARTITION BY record_id ORDER BY created_at ASC) AS rn
                    FROM pending_changes
                    WHERE direction = 'out' AND processed = false
                ) sub
                WHERE rn = 1
            ) AND direction = 'out' AND processed = false AND operation = 'UPDATE';
        """)

        count = 0
        for row in rows:
            change_id, table, record_id, operation, payload_json = row
            try:
                payload = safe_json_load(payload_json)
                if not isinstance(payload.get("id"), str) or "your-generated-id" in payload.get("id"):
                    continue

                apply_change(local_cur, table, operation, payload)

                if table == "bookings" and operation == "INSERT":
                    local_cur.execute("""
                        UPDATE pending_changes
                        SET booking_id = %s
                        WHERE record_id = %s AND table_name = 'bookings' AND booking_id IS NULL
                    """, (record_id, record_id))

                # Logga kontaktimport
                if table == "contact":
                    email = payload.get("booking_email", "(okÃ¤nd e-post)")
                    meta = safe_json_load(payload.get("metadata", {}))
                    address = meta.get("address", "(okÃ¤nd adress)")
                    print(f"ğŸ“¥ Importerad kontakt: {email} â†’ {address}")

                local_cur.execute("""
                    INSERT INTO event_log (id, source, event_type, payload, received_at)
                    VALUES (gen_random_uuid(), %s, %s, %s, now())
                """, ('sync', f"{operation.lower()}_{table}", json.dumps(payload)))

                remote_cur.execute("UPDATE pending_changes SET processed = true WHERE id = %s", [change_id])
                remote_conn.commit()
                local_conn.commit()
                count += 1

            except Exception as e:
                print(f"âŒ Fel vid synk fÃ¶r {table} (id={change_id}): {e}")
                local_conn.rollback()
                remote_conn.rollback()
                continue

    finally:
        local_cur.close()
        remote_cur.close()
        local_conn.close()
        remote_conn.close()

if __name__ == "__main__":
    sync()
END: sync_from_cloud.py

====================
ğŸ“„ Fil: sync_to_cloud.py
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ Python
ğŸ“… Senast Ã¤ndrad: 2025-05-31 19:06:54
ğŸ“ Antal rader: 220
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 3 â€“ ['import psycopg2', 'import json', 'import traceback']
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 38
ğŸ§ª TODO/FIXME: 0
====================
START: sync_to_cloud.py
import psycopg2
import json
from datetime import datetime, timezone
from config import LOCAL_DB_CONFIG, REMOTE_DB_CONFIG

def safe_json_load(data, default={}):
    try:
        return json.loads(data) if isinstance(data, str) else data
    except Exception:
        return default

def metadata_equal(meta1, meta2):
    m1 = safe_json_load(meta1)
    m2 = safe_json_load(meta2)
    return m1 == m2

def connect_db(config):
    return psycopg2.connect(**config)

def fetch_pending_changes(conn):
    with conn.cursor() as cur:
        cur.execute("""
            SELECT id, table_name, record_id, operation, payload
            FROM (
                SELECT *, ROW_NUMBER() OVER (PARTITION BY record_id ORDER BY created_at ASC) AS rn
                FROM pending_changes
                WHERE direction = 'out' AND processed = false
                  AND table_name IN ('contact', 'bookings')
            ) sub
            WHERE rn = 1
            ORDER BY created_at ASC, id
        """)
        rows = cur.fetchall()

        # Rensa Ã¤ldre UPDATE-poster med samma record_id
        cur.execute("""
            DELETE FROM pending_changes
            WHERE id NOT IN (
                SELECT id FROM (
                    SELECT id, ROW_NUMBER() OVER (PARTITION BY record_id ORDER BY created_at ASC) AS rn
                    FROM pending_changes
                    WHERE direction = 'out' AND processed = false
                ) sub
                WHERE rn = 1
            ) AND direction = 'out' AND processed = false AND operation = 'UPDATE';
        """)
        return rows

def mark_as_processed(conn, change_id):
    with conn.cursor() as cur:
        cur.execute("UPDATE pending_changes SET processed = true WHERE id = %s", (change_id,))
        conn.commit()

#
# ğŸ“ SYNC-BETEENDE: Hantering av metadata
#
# Viktigt att fÃ¶rstÃ¥ skillnaden:
#
# 1. Ã„ndring av vÃ¤rde:
#    - Exempel: "postal_code": "111 11" â†’ "115 32"
#    - Hanteras som en vanlig UPDATE (om updated_at Ã¤r nyare)
#
# 2. Ã„ndring av nyckel (etikett):
#    - Exempel: "postal_number" â†’ "postal_code"
#    - Molnet kommer *inte* ta bort "postal_number" utan force_resync
#    - LÃ¤gg till `"force_resync": true` i metadata fÃ¶r att tvinga full Ã¶verskrivning
#
# Detta minskar risken att data i molnet raderas av misstag.

def apply_change(conn, change, local_conn):
    table_name, record_id, operation, payload = change[1], change[2], change[3], change[4]
    with conn.cursor() as cur:
        data = safe_json_load(payload)

        # Skip contact records with metadata.origin != 'klrab.se'
        if table_name == 'contact' and 'metadata' in data:
            meta = safe_json_load(data['metadata'])
            if meta.get('origin') != 'klrab.se':
                print(f"âš ï¸ Skickas ej: origin != klrab.se â€“ {data.get('booking_email')}")
                mark_as_processed(local_conn, change[0])
                return

        # Ensure all values are serializable to SQL
        for k, v in data.items():
            if isinstance(v, dict):
                data[k] = json.dumps(v)

        if 'updated_at' in data:
            if isinstance(data['updated_at'], str):
                # Parse and convert to UTC if it's a string
                try:
                    dt = datetime.fromisoformat(data['updated_at'])
                    data['updated_at'] = dt.astimezone(timezone.utc).isoformat()
                except Exception as e:
                    print(f"âš ï¸ Kunde inte tolka updated_at: {data['updated_at']} ({e})")
            elif isinstance(data['updated_at'], datetime):
                data['updated_at'] = data['updated_at'].astimezone(timezone.utc).isoformat()

        if operation == 'INSERT':
            columns = ', '.join(data.keys())
            placeholders = ', '.join(['%s'] * len(data))
            values = list(data.values())
            cur.execute(
                f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders}) "
                f"ON CONFLICT (id) DO UPDATE SET "
                f"{', '.join([f'{k} = EXCLUDED.{k}' for k in data.keys() if k != 'id'])}",
                values
            )
            if table_name == 'bookings':
                with local_conn.cursor() as local_cur:
                    local_cur.execute(
                        """
                        UPDATE pending_changes
                        SET booking_id = %s
                        WHERE record_id = %s AND table_name = 'bookings' AND booking_id IS NULL
                        """,
                        (record_id, record_id)
                    )
                    local_conn.commit()

        if data.get("force_resync") is True:
            print(f"ğŸ” Force resync aktiv â€“ uppdaterar {table_name} {record_id}")

        if operation == 'UPDATE':
            # Merge metadata with existing remote value and ensure JSON string (only for UPDATE)
            if 'metadata' in data and table_name == 'contact':
                cur.execute(f"SELECT metadata FROM {table_name} WHERE id = %s", (record_id,))
                row = cur.fetchone()
                if row and row[0]:
                    existing_metadata = safe_json_load(row[0])
                else:
                    existing_metadata = {}

                incoming_metadata = safe_json_load(data['metadata'])
                if metadata_equal(existing_metadata, incoming_metadata):
                    mark_as_processed(local_conn, change[0])
                    return
                existing_metadata.update(incoming_metadata)
                changed_keys = [k for k in incoming_metadata if existing_metadata.get(k) != incoming_metadata[k]]
                if not changed_keys:
                    mark_as_processed(local_conn, change[0])
                    return
                data['metadata'] = json.dumps(existing_metadata)

            # FÃ¶rbÃ¤ttrad hantering av tidsjÃ¤mfÃ¶relse fÃ¶r updated_at
            if 'updated_at' in data and not data.get("force_resync"):
                try:
                    # SÃ¤kerstÃ¤ll att local_ts Ã¤r datetime i UTC
                    local_ts = data['updated_at']
                    if isinstance(local_ts, str):
                        local_ts = datetime.fromisoformat(local_ts)
                    if local_ts.tzinfo is None:
                        local_ts = local_ts.replace(tzinfo=timezone.utc)
                    else:
                        local_ts = local_ts.astimezone(timezone.utc)

                    cur.execute(f"SELECT updated_at FROM {table_name} WHERE id = %s", (record_id,))
                    row = cur.fetchone()
                    if row and row[0] and isinstance(row[0], datetime):
                        remote_ts = row[0]
                        if remote_ts.tzinfo is None:
                            remote_ts = remote_ts.replace(tzinfo=timezone.utc)
                        else:
                            remote_ts = remote_ts.astimezone(timezone.utc)

                        if local_ts <= remote_ts:
                            mark_as_processed(local_conn, change[0])
                            return
                except Exception:
                    pass

            if table_name == "contact" and "metadata" in data:
                local_meta = safe_json_load(data["metadata"])
                cur.execute("SELECT metadata FROM contact WHERE id = %s", (data["id"],))
                row = cur.fetchone()
                if row:
                    remote_meta = safe_json_load(row[0])
                    if remote_meta == local_meta:
                        mark_as_processed(local_conn, change[0])
                        return

            columns = ', '.join(data.keys())
            placeholders = ', '.join(['%s'] * len(data))
            values = list(data.values())
            update_keys = [k for k in data.keys() if k != 'id']
            update_set = ', '.join([f"{k} = %s" for k in update_keys])
            update_values = [data[k] for k in update_keys]
            update_values.append(record_id)
            cur.execute(
                f"UPDATE {table_name} SET {update_set} WHERE id = %s",
                update_values
            )
            print(f"âœ… UPDATE kÃ¶rd fÃ¶r {table_name} {record_id}")
            cur.execute("SELECT metadata, updated_at FROM contact WHERE id = %s", [payload["id"]])
            updated_row = cur.fetchone()
        elif operation == 'DELETE':
            cur.execute(f"DELETE FROM {table_name} WHERE id = %s", (record_id,))
        conn.commit()
        mark_as_processed(local_conn, change[0])

def sync():
    import traceback
    local_conn = connect_db(LOCAL_DB_CONFIG)
    remote_conn = connect_db(REMOTE_DB_CONFIG)

    changes = fetch_pending_changes(local_conn)
    count = 0
    for change in changes:
        try:
            apply_change(remote_conn, change, local_conn)
            count += 1
        except Exception as e:
            print(f"âŒ Misslyckades att applicera Ã¤ndring pÃ¥ {change[1]} (id={change[2]}): {e}")
            traceback.print_exc()
    
    local_conn.close()
    remote_conn.close()

if __name__ == "__main__":
    sync()
END: sync_to_cloud.py

====================
ğŸ“„ Fil: sync_static_tables.py
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ Python
ğŸ“… Senast Ã¤ndrad: 2025-04-24 17:01:52
ğŸ“ Antal rader: 61
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 2 â€“ ['import psycopg2', 'import json']
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 6
ğŸ§ª TODO/FIXME: 0
====================
START: sync_static_tables.py
from config import LOCAL_DB_CONFIG, REMOTE_DB_CONFIG
import psycopg2
import json
from datetime import datetime


TABLES = ["translation", "booking_settings"]


def connect_db(config):
    return psycopg2.connect(**config)


def fetch_all_from_local(conn, table):
    with conn.cursor() as cur:
        cur.execute(f"SELECT * FROM {table}")
        colnames = [desc[0] for desc in cur.description]
        rows = cur.fetchall()
        return colnames, rows


def clear_remote_table(conn, table):
    with conn.cursor() as cur:
        cur.execute(f"DELETE FROM {table}")
        conn.commit()


def insert_to_remote(conn, table, columns, rows):
    with conn.cursor() as cur:
        placeholders = ', '.join(['%s'] * len(columns))
        colnames = ', '.join(columns)
        for row in rows:
            # Hantera jsonb-vÃ¤rden som json-strÃ¤ngar
            formatted_row = []
            for i, col in enumerate(columns):
                value = row[i]
                if table == 'booking_settings' and col == 'value':
                    formatted_row.append(json.dumps(value))
                else:
                    formatted_row.append(value)
            cur.execute(f"INSERT INTO {table} ({colnames}) VALUES ({placeholders})", formatted_row)
        conn.commit()


def sync_static_tables():
    local_conn = connect_db(LOCAL_DB_CONFIG)
    remote_conn = connect_db(REMOTE_DB_CONFIG)

    for table in TABLES:
        print(f"\nâ³ Synkar tabell: {table}...")
        columns, rows = fetch_all_from_local(local_conn, table)
        clear_remote_table(remote_conn, table)
        insert_to_remote(remote_conn, table, columns, rows)
        print(f"âœ… Klar med tabell: {table} ({len(rows)} rader)")

    local_conn.close()
    remote_conn.close()


if __name__ == "__main__":
    sync_static_tables()

END: sync_static_tables.py

====================
ğŸ“„ Fil: sync.py
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ Python
ğŸ“… Senast Ã¤ndrad: 2025-05-31 19:07:46
ğŸ“ Antal rader: 90
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 2 â€“ ['import psycopg2', 'import json']
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 9
ğŸ§ª TODO/FIXME: 0
====================
START: sync.py
import psycopg2
import json
from datetime import datetime
from config import LOCAL_DB_CONFIG

def safe_json_load(data, default={}):
    try:
        return json.loads(data) if isinstance(data, str) else data
    except Exception:
        return default

def metadata_equal(meta1, meta2):
    m1 = safe_json_load(meta1)
    m2 = safe_json_load(meta2)
    return m1 == m2

# Anslutning till lokal PostgreSQL
conn = psycopg2.connect(**LOCAL_DB_CONFIG)
cursor = conn.cursor()

# Rensa Ã¤ldre UPDATE-rader (endast senaste behÃ¶vs per record_id)
cursor.execute("""
    DELETE FROM pending_changes pc
    WHERE operation = 'UPDATE'
      AND processed = false
      AND direction = 'out'
      AND id NOT IN (
        SELECT id FROM (
          SELECT id,
                 ROW_NUMBER() OVER (PARTITION BY record_id ORDER BY created_at DESC) AS rn
          FROM pending_changes
          WHERE operation = 'UPDATE'
            AND processed = false
            AND direction = 'out'
        ) sub
        WHERE rn = 1
      );
""")

# HÃ¤mta EN Ã¤ndring per kontakt (record_id) â€“ endast senaste per kontakt exporteras med hjÃ¤lp av ROW_NUMBER()
cursor.execute("""
    SELECT id, table_name, record_id, operation, payload, created_at
    FROM (
        SELECT *, ROW_NUMBER() OVER (PARTITION BY record_id ORDER BY created_at DESC) as rn
        FROM pending_changes
        WHERE processed = false AND direction = 'out'
    ) sub
    WHERE rn = 1
""")

rows = cursor.fetchall()

# Filtrera bort poster dÃ¤r metadata Ã¤r identisk med befintlig kontakt
filtered_rows = []
for row in rows:
    change_id, table, record_id, operation, payload, created_at = row
    data = json.loads(payload) if isinstance(payload, str) else payload
    if table == "contact" and operation == "UPDATE":
        try:
            cursor.execute("SELECT metadata FROM contact WHERE id = %s", (record_id,))
            result = cursor.fetchone()
            if result:
                incoming_metadata = data.get("metadata")
                if metadata_equal(result[0], incoming_metadata):
                    continue
        except Exception as e:
            print(f"âš ï¸ Kunde inte jÃ¤mfÃ¶ra metadata fÃ¶r {record_id}: {e}")
    filtered_rows.append(row)
rows = filtered_rows

# Skapa exportformat
export = []
for row in rows:
    change_id, table, record_id, operation, payload, created_at = row
    export.append({
        "change_id": str(change_id),
        "table": table,
        "operation": operation,
        "data": payload
    })

# Spara till JSON-fil med tidsstÃ¤mpel
if export:
    first_type = export[0]["table"] if export else "unknown"
    filename = f"sync_outbox/{datetime.now().strftime('%Y%m%d_%H%M%S')}_{first_type}.json"
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(export, f, indent=2, ensure_ascii=False)

cursor.close()
conn.close()

END: sync.py

====================
ğŸ“„ Fil: sync_all.py
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ Python
ğŸ“… Senast Ã¤ndrad: 2025-05-31 19:08:59
ğŸ“ Antal rader: 171
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 7 â€“ ['import os', 'import subprocess', 'import sys', 'import psycopg2', 'import json', 'import socket', 'import traceback']
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 19
ğŸ§ª TODO/FIXME: 0
====================
START: sync_all.py
BASE = "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api"


import os
import subprocess
from datetime import datetime
import sys
import psycopg2
import json

# Delad json- och metadata-funktionalitet som anvÃ¤nds i flera synkmoduler
def safe_json_load(data, default={}):
    try:
        return json.loads(data) if isinstance(data, str) else data
    except Exception:
        return default

def metadata_equal(meta1, meta2):
    m1 = safe_json_load(meta1)
    m2 = safe_json_load(meta2)
    return m1 == m2

log_dir = "/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot"
log_out = os.path.join(log_dir, "macspot_sync.log")
log_err = os.path.join(log_dir, "macspot_sync_error.log")

# Se till att loggfilerna existerar
for path in [log_out, log_err]:
    if not os.path.exists(path):
        with open(path, 'w'):
            pass

# Skriv ut manuell/automatisk kÃ¶rningsinfo till loggen
is_manual = sys.stdout.isatty()
sys.stdout = open(log_out, 'a')
sys.stderr = open(log_err, 'a')
if is_manual:
    print(f"ğŸ–ï¸ Manuell kÃ¶rning: {datetime.now().isoformat()}")
else:
    print(f"ğŸ¤– Automatisk kÃ¶rning via launchd: {datetime.now().isoformat()}")

def run_script(name, script_path):
    subprocess.run(["python", f"{BASE}/{script_path}"], check=True)

try:
    start_time = datetime.now()
    def is_database_online(host, port):
        import socket
        try:
            socket.create_connection((host, port), timeout=2)
            return True
        except:
            return False

    def run_healthcheck():
        try:
            subprocess.run(["python", f"{BASE}/healthcheck_sync.py"], check=True)
        except Exception as e:
            print(f"âŒ Healthcheck misslyckades: {e}")

    # Kontrollera att bÃ¥da databaser Ã¤r online innan sync startar
    if not is_database_online("localhost", 5433):
        print("âŒ Lokal databas Ã¤r inte tillgÃ¤nglig (localhost:5433)")
        exit(1)

    if not is_database_online("macspotpg.postgres.database.azure.com", 5432):
        print("âŒ Azure-databasen Ã¤r inte tillgÃ¤nglig (macspotpg.postgres.database.azure.com:5432)")
        exit(1)

    print(f"ğŸ“Œ KÃ¶rning initierad: {datetime.now().isoformat()}")

    print("ğŸ§ª KÃ¶r healthcheck_sync.py...")
    run_healthcheck()

    print(f"\nğŸ”„ [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Startar fullstÃ¤ndig synk...")

    scripts_part1 = [
        ("ğŸŸ¡ KÃ¶r sync.py...", "sync.py"),
        ("ğŸŸ¢ KÃ¶r sync_to_cloud.py...", "sync_to_cloud.py")
    ]

    for msg, script in scripts_part1:
        run_script(msg, script)

    scripts_part2 = [
        ("ğŸ”µ KÃ¶r sync_from_cloud.py...", "sync_from_cloud.py")
    ]

    for msg, script in scripts_part2:
        run_script(msg, script)

    today_prefix = datetime.now().strftime('%Y%m%d')
    outbox_dir = os.path.join(BASE, 'sync_outbox')
    files = [f for f in os.listdir(outbox_dir) if f.startswith(today_prefix)]
    files_with_type = [f for f in files if len(f.split("_")) >= 3]
    num_changes = len(files_with_type)

    if num_changes == 0:
        print("â„¹ï¸ Ingen fÃ¶rÃ¤ndring hittades att synka.")
        print("ğŸ“­ Inga fler Ã¤ndringar kvar i pending_changes.")
    else:
        print(f"ğŸ“¤ Totalt {num_changes} Ã¤ndring(ar) skickades till molnet:")
        files = [f for f in sorted(os.listdir(outbox_dir)) if f.startswith(today_prefix)]
        summary = {}
        for f in files:
            parts = f.split("_")
            if len(parts) >= 3:
                typ = parts[2].split(".")[0]
                summary[typ] = summary.get(typ, 0) + 1

        if summary:
            print("ğŸ§¾ Sammanfattning per typ:")
            for typ, count in summary.items():
                print(f"   â€¢ {typ}: {count} st")

        print("ğŸ“Š Kontroll av Ã¥terstÃ¥ende Ã¤ndringar i pending_changes...")

        # Lokalt
        local = psycopg2.connect(
            dbname="macspot",
            user="postgres",
            host="localhost",
            port=5433
        )
        cur_local = local.cursor()
        cur_local.execute("""
            SELECT COUNT(*) FROM pending_changes
            WHERE direction = 'out' AND processed = false
        """)
        out_local = cur_local.fetchone()[0]
        cur_local.execute("""
            SELECT COUNT(*) FROM pending_changes
            WHERE direction = 'out' AND processed = false
            GROUP BY record_id
        """)
        print(f"   â€¢ Lokalt â†’ molnet: {out_local} Ã¤ndring(ar) kvar Ã¶ver {cur_local.rowcount} kontakt(er).")
        cur_local.close()
        local.close()

        # Molnet
        cloud = psycopg2.connect(
            dbname="postgres",
            user="daniel",
            host="macspotpg.postgres.database.azure.com",
            port=5432
        )
        cur_cloud = cloud.cursor()
        cur_cloud.execute("""
            SELECT COUNT(*) FROM pending_changes
            WHERE direction = 'out' AND processed = false
        """)
        out_cloud = cur_cloud.fetchone()[0]
        cur_cloud.execute("""
            SELECT COUNT(*) FROM pending_changes
            WHERE direction = 'out' AND processed = false
            GROUP BY record_id
        """)
        cur_cloud.close()
        cloud.close()

    print(f"\nâœ… [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] FullstÃ¤ndig synk kÃ¶rd.")

except Exception as e:
    import traceback
    print("âŒ Ett ovÃ¤ntat fel intrÃ¤ffade under kÃ¶rningen:")
    print(traceback.format_exc())

finally:
    print(f"ğŸ KÃ¶rning avslutad: {datetime.now().isoformat()}")
    duration = datetime.now() - start_time
    print(f"â±ï¸ Total kÃ¶rtid: {int(duration.total_seconds())} sekunder")
END: sync_all.py

====================
ğŸ“„ Fil: macspot.sync.plist
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ“„ OkÃ¤nt format
ğŸ“… Senast Ã¤ndrad: 2025-05-31 19:10:02
ğŸ“ Antal rader: 42
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 0 â€“ Inga
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 0
ğŸ§ª TODO/FIXME: 0
====================
START: macspot.sync.plist
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" 
  "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
  <key>Label</key>
  <string>com.macspot.sync</string>

  <key>ProgramArguments</key>
  <array>
    <string>/Users/danielkallberg/Documents/KLR_AI/venv/bin/python</string>
    <string>/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api/sync_all.py</string>
  </array>

  <key>WorkingDirectory</key>
  <string>/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot-api</string>

  <key>StartCalendarInterval</key>
  <array>
    <dict><key>Minute</key><integer>0</integer></dict>
    <dict><key>Minute</key><integer>5</integer></dict>
    <dict><key>Minute</key><integer>10</integer></dict>
    <dict><key>Minute</key><integer>15</integer></dict>
    <dict><key>Minute</key><integer>20</integer></dict>
    <dict><key>Minute</key><integer>25</integer></dict>
    <dict><key>Minute</key><integer>30</integer></dict>
    <dict><key>Minute</key><integer>35</integer></dict>
    <dict><key>Minute</key><integer>40</integer></dict>
    <dict><key>Minute</key><integer>45</integer></dict>
    <dict><key>Minute</key><integer>50</integer></dict>
    <dict><key>Minute</key><integer>55</integer></dict>
  </array>

  <key>RunAtLoad</key>
  <true/>

  <key>StandardOutPath</key>
  <string>/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot_sync.log</string>
  <key>StandardErrorPath</key>
  <string>/Users/danielkallberg/Documents/KLR_AI/Projekt_MacSpot/macspot_sync_error.log</string>
</dict>
</plist>
END: macspot.sync.plist

====================
ğŸ“„ Fil: healthcheck_sync.py
ğŸ“‚ Kodtyp: ğŸ“„ Ã–vrigt
ğŸ—‚ Filtyp: ğŸ Python
ğŸ“… Senast Ã¤ndrad: 2025-05-31 18:54:39
ğŸ“ Antal rader: 56
ğŸ§© Antal funktioner: 0
ğŸ’¬ KommentarstÃ¤ckning: 0 rader (0.0%)
ğŸ“¥ Imports: 2 â€“ ['import psycopg2', 'import sys']
ğŸ” LÃ¤ngsta funktion: 0 rader
ğŸ§  KomplexitetspoÃ¤ng: 4
ğŸ§ª TODO/FIXME: 0
====================
START: healthcheck_sync.py
# ğŸ“„ FÃ¶rbÃ¤ttrad version av healthcheck_sync.py

import psycopg2
from config import LOCAL_DB_CONFIG, REMOTE_DB_CONFIG
from datetime import datetime
import sys

__version__ = "1.0.1"

def get_pending_count(conn, label):
    with conn.cursor() as cur:
        cur.execute("""
            SELECT COUNT(*) FROM pending_changes
            WHERE direction = 'out' AND processed = false
        """)
        count = cur.fetchone()[0]
        print(f"ğŸ” {label}: {count} osynkade fÃ¶rÃ¤ndringar")
        return count

def check_db_connection(name, config):
    try:
        start = datetime.utcnow()
        conn = psycopg2.connect(**config)
        latency = (datetime.utcnow() - start).total_seconds()
        print(f"âœ… Anslutning till {name} OK (latens: {latency:.2f} sek)")
        return conn
    except Exception as e:
        print(f"âŒ Fel vid anslutning till {name}: {e}")
        return None

def main():
    print(f"\nğŸ“‹ Healthcheck MacSpot sync v{__version__} â€“ {datetime.utcnow().isoformat()} UTC\n")
    errors = 0

    local_conn = check_db_connection("Lokal databas", LOCAL_DB_CONFIG)
    if local_conn:
        get_pending_count(local_conn, "Lokal â†’ moln")
        local_conn.close()
    else:
        errors += 1

    remote_conn = check_db_connection("Molndatabas", REMOTE_DB_CONFIG)
    if remote_conn:
        get_pending_count(remote_conn, "Moln â†’ lokal")
        remote_conn.close()
    else:
        errors += 1

    if errors > 0:
        print(f"\nâŒ Healthcheck avslutades med {errors} fel.\n")
        sys.exit(1)
    else:
        print(f"\nâœ… Healthcheck genomfÃ¶rd utan fel.\n")

if __name__ == "__main__":
    main()
END: healthcheck_sync.py

ğŸ“ KONFIGURATIONSFILER (function.json / host.json / package.json / .funcignore)
====================================

ğŸ“„ .funcignore
   # Exclude dev-only files and folders
   .git
   .vscode
   .env
   *.log
   test/
   tests/
   
   # Explicitly include all required files and folders
   !host.json
   !package.json
   !package-lock.json
   
   !node_modules/
   !node_modules/**
   
   !shared/
   !shared/**
   
   !bookings/
   !bookings/**
   !getavailableslots/
   !getavailableslots/**
   !validate_contact/
   !validate_contact/**
   !meeting_types/
   !meeting_types/**
   !refreshCalendarOrigins/
   !refreshCalendarOrigins/**
   !refreshTravelTimes/
   !refreshTravelTimes/**
   !booking_settings/
   !booking_settings/**
   !test_azurecloud/
   !test_azurecloud/**
   !trackingPixel/
   !trackingPixel/**
ğŸ“„ booking_settings/function.json
   {
     "bindings": [
       {
         "authLevel": "anonymous",
         "type": "httpTrigger",
         "direction": "in",
         "name": "req",
         "methods": ["get"],
         "route": "booking_settings"
       },
       {
         "type": "http",
         "direction": "out",
         "name": "res"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ bookings/function.json
   {
     "bindings": [
       {
         "authLevel": "anonymous",
         "type": "httpTrigger",
         "direction": "in",
         "name": "req",
         "methods": ["post", "options"],
         "route": "bookings"
       },
       {
         "type": "http",
         "direction": "out",
         "name": "res"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ getavailableslots/function.json
   {
     "bindings": [
       {
         "authLevel": "anonymous",
         "type": "httpTrigger",
         "direction": "in",
         "name": "req",
         "methods": ["post", "options"],
         "route": "getavailableslots"
       },
       {
         "type": "http",
         "direction": "out",
         "name": "res"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ host.json
   {
     "version": "2.0",
     "extensionBundle": {
       "id": "Microsoft.Azure.Functions.ExtensionBundle",
       "version": "[4.*, 5.0.0)"
     },
     "extensions": {
       "http": {
         "cors": {
           "allowedOrigins": [
             "https://www.klrab.se"
           ],
           "supportCredentials": false
         }
       }
     }
   }
ğŸ“„ meeting_types/function.json
   {
     "bindings": [
       {
         "authLevel": "anonymous",
         "type": "httpTrigger",
         "direction": "in",
         "name": "req",
         "methods": [ "get" ],
         "route": "meeting_types"
       },
       {
         "type": "http",
         "direction": "out",
         "name": "res"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ package.json
   {
     "name": "macspot-api",
     "version": "1.0.0",
     "description": "Azure Functions backend fÃ¶r MacSpot CRM/ERP",
     "scripts": {
       "start": "func start",
       "dev": "func start --verbose",
       "deploy": "func azure functionapp publish macspotbackend",
       "build": "echo 'Nothing to build'"
     },
     "dependencies": {
       "@azure/functions": "^4.7.0",
       "@azure/msal-node": "^3.5.1",
       "@microsoft/microsoft-graph-client": "^3.0.0",
       "date-holidays": "^3.24.3",
       "dav": "^1.8.0",
       "dotenv": "^16.5.0",
       "isomorphic-fetch": "^3.0.0",
       "jsonwebtoken": "^9.0.0",
       "luxon": "^3.4.4",
       "node-fetch": "^2.7.0",
       "node-ical": "^0.20.1",
       "p-limit": "^6.2.0",
       "pg": "^8.15.6",
       "uuid": "^9.0.0",
       "xml2js": "^0.6.2"
     }
   }

ğŸ“„ refreshCalendarOrigins/function.json
   {
     "bindings": [
       {
         "name": "myTimer",
         "type": "timerTrigger",
         "direction": "in",
         "schedule": "0 0 * * * *"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ refreshTravelTimes/function.json
   {
     "bindings": [
       {
         "name": "myTimer",
         "type": "timerTrigger",
         "direction": "in",
         "schedule": "0 0 * * * *"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ test_azurecloud/function.json
   {
     "bindings": [
       {
         "authLevel": "anonymous",
         "type": "httpTrigger",
         "direction": "in",
         "name": "req",
         "methods": ["get"],
         "route": "test_azurecloud"
       },
       {
         "type": "http",
         "direction": "out",
         "name": "res"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“„ validate_contact/function.json
   {
     "bindings": [
       {
         "authLevel": "anonymous",
         "type": "httpTrigger",
         "direction": "in",
         "name": "req",
         "methods": ["get", "post"],
         "route": "validate_contact"
       },
       {
         "type": "http",
         "direction": "out",
         "name": "res"
       }
     ],
     "scriptFile": "index.js"
   }
ğŸ“ˆ SUMMERING AV ALLA JS-FILER
====================================
ğŸ“ Totalt antal rader kod: 784
ğŸ§© Totalt antal funktioner: 0
ğŸ§  Total komplexitetspoÃ¤ng: 96
ğŸ§ª Antal TODO/FIXME totalt: 0

ğŸ“Š Per fil:
fil,rader,funktioner,komplexitet,kommentarer,imports
sync_from_cloud.py,144,0,20,0,2
sync_to_cloud.py,220,0,38,0,3
sync_static_tables.py,61,0,6,0,2
sync.py,90,0,9,0,2
sync_all.py,171,0,19,0,7
macspot.sync.plist,42,0,0,0,0
healthcheck_sync.py,56,0,4,0,2
ğŸ“Š MOLNDATABAS (Azure) â€“ STRUKTUR & INNEHÃ…LL
====================================

ğŸ“ Tabell: slot_cache
  â€¢ created_at (timestamp without time zone)
  â€¢ slot_day (date)
  â€¢ slots (jsonb)
  â€¢ id (uuid)
  â€¢ meeting_length (integer)
  â€¢ booking_email (text)
  â€¢ meeting_type (text)
  â€¢ slot_part (text)
  ğŸ”‘ [p] slot_cache_pkey: PRIMARY KEY (id)

ğŸ“ Tabell: calendar_origin_cache
  â€¢ created_at (timestamp without time zone)
  â€¢ timestamp (timestamp with time zone)
  â€¢ event_date (date)
  â€¢ id (integer)
  â€¢ end_time (timestamp without time zone)
  â€¢ address (text)
  â€¢ source (text)
  ğŸ”‘ [c] calendar_origin_cache_source_check: CHECK ((source = ANY (ARRAY['Apple Calendar'::text, 'Microsoft 365'::text])))
  ğŸ”‘ [p] calendar_origin_cache_pkey: PRIMARY KEY (id)

ğŸ“ Tabell: available_slots_cache
  â€¢ id (uuid)
  â€¢ travel_time_min (integer)
  â€¢ generated_at (timestamp without time zone)
  â€¢ expires_at (timestamp without time zone)
  â€¢ meeting_length (integer)
  â€¢ slot_day (date)
  â€¢ slot_score (integer)
  â€¢ meeting_type (text)
  â€¢ slot_part (text)
  â€¢ slot_iso (text)
  ğŸ”‘ [p] available_slots_cache_pkey: PRIMARY KEY (id)

ğŸ“ Tabell: travel_time_cache
  â€¢ travel_minutes (integer)
  â€¢ updated_at (timestamp with time zone)
  â€¢ is_fallback (boolean)
  â€¢ hour (integer)
  â€¢ created_at (timestamp with time zone)
  â€¢ to_address (text)
  â€¢ from_address (text)
  ğŸ”‘ [u] unique_travel_key: UNIQUE (from_address, to_address, hour)
  ğŸ§ª Topp 5 rader:
    - from_address=Taxgatan 4, 115 45 Stockholm, to_address=Maria Skolgata 79A, 118 53 Stockholm, hour=10, travel_minutes=19, created_at=2025-05-30 21:00:01.127523+00:00, updated_at=2025-05-30 21:00:01.127523+00:00, is_fallback=False
    - from_address=Taxgatan 4, 115 45 Stockholm, to_address=Maria Skolgata 79A, 118 53 Stockholm, hour=14, travel_minutes=19, created_at=2025-05-30 21:00:01.927463+00:00, updated_at=2025-05-30 21:00:01.927463+00:00, is_fallback=False

ğŸ“ Tabell: event_log
  â€¢ received_at (timestamp with time zone)
  â€¢ record_id (uuid)
  â€¢ timestamp (timestamp with time zone)
  â€¢ booking_id (uuid)
  â€¢ id (uuid)
  â€¢ payload (jsonb)
  â€¢ action (text)
  â€¢ event_type (text)
  â€¢ source (text)
  â€¢ table_name (text)
  ğŸ”‘ [p] event_log_pkey: PRIMARY KEY (id)

ğŸ“ Tabell: booking_settings
  â€¢ value (jsonb)
  â€¢ updated_at (timestamp with time zone)
  â€¢ key (text)
  â€¢ value_type (text)
  ğŸ”‘ [u] unique_key: UNIQUE (key)
  ğŸ§ª Topp 5 rader:
    - key=default_meeting_length_atoffice, value=[60, 90], value_type=array, updated_at=2025-04-23 12:48:49.778155+00:00
    - key=default_meeting_length_digital, value=[10, 20, 60], value_type=array, updated_at=2025-04-23 12:48:49.778155+00:00
    - key=default_meeting_subject, value=MÃ¶te med KLRA LedningsrÃ¥dgivning, value_type=string, updated_at=2025-05-25 10:37:53.619684+00:00
    - key=default_language, value=sv, value_type=string, updated_at=2025-05-25 10:37:53.619684+00:00
    - key=default_meeting_length_atclient, value=[90, 180, 270, 360], value_type=array, updated_at=2025-04-23 12:48:49.778155+00:00

ğŸ“ Tabell: translation
  â€¢ key (character varying)
  â€¢ sv (text)
  â€¢ en (text)
  ğŸ§ª Topp 5 rader:
    - key=error_min_duration_fysiskt_kund, sv=MÃ¶testiden fÃ¶r 'Fysiskt hos kund' mÃ¥ste vara minst {{minutes}} minuter. Du visste det redan., en=The meeting time for 'On-site at customer' must be at least {{minutes}} minutes. You knew that.
    - key=error_min_duration_fysiskt_mig, sv=MÃ¶testiden fÃ¶r 'Fysiskt hos mig' mÃ¥ste vara minst {{minutes}} minuter. Annars hinner vi bara sÃ¤ga hej., en=The meeting time for 'At my office' must be at least {{minutes}} minutes. Otherwise, weâ€™ll only have time to say hello.
    - key=email_body_booking_received, sv=Hej {{name}}! Vi har tagit emot din bokning fÃ¶r {{meeting_type}} mellan {{start_time}} och {{end_time}}. Ingen panik â€“ vi Ã¥terkommer med bekrÃ¤ftelse. / Daniel, en=Hello {{name}}, Weâ€™ve received your booking for {{meeting_type}} between {{start_time}} and {{end_time}}. No need to panic â€“ weâ€™ll confirm shortly. / Daniel
    - key=email_body_booking_confirmed, sv=Hej {{name}}! Din bokning fÃ¶r {{meeting_type}} mellan {{start_time}} och {{end_time}} Ã¤r nu spikad. Ser fram emot det! / Daniel, en=Hello {{name}}, Your booking for {{meeting_type}} between {{start_time}} and {{end_time}} is now locked in. Looking forward! / Daniel
    - key=email_body_booking_cancelled, sv=Hej {{name}}! Din bokning fÃ¶r {{meeting_type}} mellan {{start_time}} och {{end_time}} Ã¤r avbokad. HÃ¶r av dig om du vill hitta en ny tid. / Daniel, en=Hello {{name}}, Your booking for {{meeting_type}} between {{start_time}} and {{end_time}} has been cancelled. Let me know if you'd like a new one. / Daniel

ğŸ“ Tabell: bookings
  â€¢ start_time (timestamp with time zone)
  â€¢ end_time (timestamp with time zone)
  â€¢ id (uuid)
  â€¢ updated_at (timestamp with time zone)
  â€¢ metadata (jsonb)
  â€¢ created_at (timestamp with time zone)
  â€¢ contact_id (uuid)
  â€¢ meeting_type (text)
  â€¢ booking_email (text)
  ğŸ”‘ [p] bookings_pkey: PRIMARY KEY (id)
  ğŸ”‘ [f] fk_bookings_contact: FOREIGN KEY (contact_id) REFERENCES contact(id) ON DELETE SET NULL

ğŸ“ Tabell: pending_changes
  â€¢ booking_id (uuid)
  â€¢ processed (boolean)
  â€¢ created_at (timestamp with time zone)
  â€¢ payload (jsonb)
  â€¢ id (uuid)
  â€¢ record_id (uuid)
  â€¢ table_name (text)
  â€¢ operation (text)
  â€¢ change_type (text)
  â€¢ direction (text)
  ğŸ”‘ [p] pending_changes_pkey: PRIMARY KEY (id)
  ğŸ”‘ [f] fk_pending_changes_booking_id: FOREIGN KEY (booking_id) REFERENCES bookings(id) ON DELETE CASCADE

ğŸ“ Tabell: contact
  â€¢ metadata (jsonb)
  â€¢ created_at (timestamp with time zone)
  â€¢ id (uuid)
  â€¢ updated_at (timestamp with time zone)
  â€¢ booking_email (text)
  â€¢ email (text)
  ğŸ”‘ [p] contact_pkey: PRIMARY KEY (id)

